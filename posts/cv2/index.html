<!doctype html>
<html lang="en-us">
  <head>
    <title>Journey into Computer Vision and Machine Learning Part II // My Nguyen Blog</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.111.3">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="My Nguyen" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.3c3c186cd62e563ad6e2f00a89dbee656ab912d1d46f856b5605dd0232521e2a.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Journey into Computer Vision and Machine Learning Part II"/>
<meta name="twitter:description" content="Welcome to the second part of our ongoing journey into computer vision and machine learning. In this blog post, I am thrilled to provide an update on our progress in learning annotation techniques for creating segmentation masks in instance segmentation. Instance segmentation, which involves detecting object outlines, has been a central focus of our exploration. Over the past month, our dedicated team has been working together, utilizing CVAT as our annotation tool, to produce datasets enriched with segmentation masks."/>

    <meta property="og:title" content="Journey into Computer Vision and Machine Learning Part II" />
<meta property="og:description" content="Welcome to the second part of our ongoing journey into computer vision and machine learning. In this blog post, I am thrilled to provide an update on our progress in learning annotation techniques for creating segmentation masks in instance segmentation. Instance segmentation, which involves detecting object outlines, has been a central focus of our exploration. Over the past month, our dedicated team has been working together, utilizing CVAT as our annotation tool, to produce datasets enriched with segmentation masks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://mynguy.github.io/posts/cv2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-01T20:15:24-04:00" />
<meta property="article:modified_time" content="2023-05-01T20:15:24-04:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="http://mynguy.github.io"><img class="app-header-avatar" src="https://media.licdn.com/dms/image/C4E03AQG-9BdIJ7p7Kg/profile-displayphoto-shrink_800_800/0/1668009004667?e=1690416000&amp;v=beta&amp;t=tL6kEdyNHpBGk395rVZBZ1J4DUkxeBYxNllEzAwop40" alt="My Nguyen" /></a>
      <span class="app-header-title">My Nguyen Blog</span>
      <p>Upcoming computer science graduate with a passion in machine learning and software development</p>
      <div class="app-header-social">
        
          <a href="https://github.com/mynguy/" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>Github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg>
          </a>
        
          <a href="https://www.linkedin.com/in/mytoannguyen/" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>LinkedIn</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Journey into Computer Vision and Machine Learning Part II</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 1, 2023
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div>
      </div>
    </header>
    <div class="post-content">
      <p>Welcome to the second part of our ongoing journey into computer vision and machine learning. In this blog post, I am thrilled to provide an update on our progress in learning annotation techniques for creating segmentation masks in instance segmentation. Instance segmentation, which involves detecting object outlines, has been a central focus of our exploration. Over the past month, our dedicated team has been working together, utilizing CVAT as our annotation tool, to produce datasets enriched with segmentation masks. Our ultimate objective is to accurately detect specific objects in alignment with our project&rsquo;s goals.</p>
<p><strong>Learning Annotation Techniques with CVAT:</strong>
In our pursuit of instance segmentation, we have diligently learned annotation techniques using the versatile tool, CVAT. This robust annotation toolset has equipped us with the necessary skills to create precise segmentation masks. Through collaborative efforts and continuous learning, we have mastered the art of outlining and labeling objects of interest in our datasets. These segmentation masks play a crucial role in training our models to accurately detect and analyze objects.</p>
<p>With the aid of CVAT, we have made significant strides in producing datasets brimming with detailed segmentation masks. These masks provide invaluable information about object boundaries and outlines within the images. By leveraging these datasets, we are poised to train our models to identify and classify specific objects with enhanced precision and accuracy. Our project&rsquo;s overarching goal revolves around detecting and analyzing these objects, and the creation of these high-quality datasets marks a significant milestone in our journey.</p>
<p><strong>Overcoming Challenges:</strong>
Throughout our exploration, we encountered a challenge related to the conversion of segmentation masks to polygons. The tutorial and training materials we found online provided scripts that were designed to work with one class projects only. To address this limitation, I took the initiative to develop my own version of the script capable of handling multiple classes. The code is readily available on my GitHub repository, specifically tailored for users of CVAT who are annotating for segmentation in YOLOv8 format. I encourage you to explore and utilize this code for your own projects.</p>
<p>In our pursuit of efficient annotation, we have embraced cutting-edge technology. Thanks to Meta AI, annotation has become significantly faster and more streamlined through the use of SAM (Segment Anything), an innovative solution that employs AI to automate the annotation process. SAM has revolutionized the way we annotate and has resulted in cleaner and more efficient dataset creation. This remarkable advancement has accelerated our progress and enabled us to focus on further aspects of our project.</p>
<p><strong>Future Prospects and Continued Progress:</strong>
As we forge ahead in our computer vision and machine learning journey, we remain passionate about the incredible possibilities that instance segmentation holds. Our expertise in annotation techniques, bolstered by the powerful capabilities of CVAT and our customized conversion script, empowers us to unlock new levels of object detection accuracy. Additionally, the integration of Meta AI&rsquo;s SAM has transformed the annotation process, elevating our efficiency and productivity. We are excited to continue this journey and share more updates in the future.</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
